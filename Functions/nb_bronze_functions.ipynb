{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "51edc3bd-7b43-4333-bfbe-17376e2225cb",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Cabeçalho\n",
    "### Objetivo\n",
    "\n",
    "Funções para a extração dos dados das APIs de dados abertos da Câmara dos Deputados.\n",
    "\n",
    "Após extração, cada função será acionada nos respectivos notebooks.\n",
    "\n",
    "### Sobre\n",
    "**Data de crição:** 26/09/2025\n",
    "\n",
    "**Responsável:** Wandrieli Nery Barbosa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "892bcd86-37ce-4785-a2d5-95e7afe2383c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%run /Users/wandrieli.89@gmail.com/projeto_tiller/Parametros/nb_parametros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ec2ff9a2-6677-4839-b87d-c65c111ad217",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%run /Users/wandrieli.89@gmail.com/projeto_tiller/Parametros/nb_catalag_schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0802c3d4-d2fd-4e6d-9a73-c84c000893fb",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#Definição do catalog e schema bronze (importado)\n",
    "set_catalog_and_schema_bronze(catalog=\"tiller\", schema=\"bronze\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "938b61bc-5b70-46df-a3e5-8bc8c8111367",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Requisição segura"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "collapsed": true,
     "inputWidgets": {},
     "nuid": "c0160f42-fffb-4493-bcbd-9c5e03ed29ba",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#Função segura para extração com retry e tratamento de erro \n",
    "def safe_get(url, params, tentativas=3, espera=5, timeout=30):\n",
    "    \n",
    "    \"\"\"\n",
    "    Busca segura necessária para novas requisições e tratamento de erros (erros de timeout)\n",
    "    \"\"\"\n",
    "\n",
    "    for i in range(tentativas):\n",
    "        try:\n",
    "            response = requests.get(\n",
    "                url, params=params, headers={\"accept\": \"application/json\"}, timeout=timeout\n",
    "            )\n",
    "            response.raise_for_status()\n",
    "            return response\n",
    "        except requests.exceptions.HTTPError as e:\n",
    "            print(f\"[ERRO HTTP] Tenativa {i+1}/{tentativas} - {e}\")\n",
    "        except requests.exceptions.RequestException as e:\n",
    "            print(f\"[ERRO REDE] Tenativa {i+1}/{tentativas} - {e}\")\n",
    "        time.sleep(espera)\n",
    "    print(f\"Falha ao acessar {url} com params={params}\")\n",
    "    return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "037587a8-1395-4452-9a55-a01cafd3df60",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Funções nb_deputados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "079e41ae-6513-48c9-adb3-d62a568e7fef",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "URL_DEPUTADOS = \"https://dadosabertos.camara.leg.br/api/v2/deputados\"\n",
    "\n",
    "def get_deputados(pagina=1, itens=100):\n",
    "   \n",
    "    \"\"\"\n",
    "    Requisição para API\n",
    "    pagina: número da página\n",
    "    itens: número de itens por página (máx 100)\n",
    "    Retorna a lista de deputados\n",
    "    \"\"\"\n",
    "\n",
    "    url = f\"{URL_DEPUTADOS}?pagina={pagina}&itens={itens}\"\n",
    "    response = requests.get(url, headers={\"accept\": \"application/json\"})\n",
    "    response.raise_for_status()\n",
    "    return response.json()[\"dados\"]\n",
    "\n",
    "\n",
    "def get_all_deputados(itens_por_pagina=100, limite_paginas=None):\n",
    "    \n",
    "    \"\"\"\n",
    "    Busca todos os deputados da API (com paginação).\n",
    "    itens_por_pagina: máximo de registros por página (default 100)\n",
    "    limite_paginas: Quais páginas, onde None = todas disponíveis\n",
    "    lista todos os deputados\n",
    "    \"\"\"\n",
    "\n",
    "    deputados = []\n",
    "    pagina = 1\n",
    "    while True:\n",
    "        dados = get_deputados(pagina=pagina, itens=itens_por_pagina)\n",
    "        if not dados:  \n",
    "            break\n",
    "        deputados.extend(dados)\n",
    "        pagina += 1\n",
    "        if limite_paginas and pagina > limite_paginas:\n",
    "            break\n",
    "    return deputados\n",
    "\n",
    "\n",
    "def deputados_to_dataframe(deputados):\n",
    "    \n",
    "    \"\"\"\n",
    "    Converte lista de deputados para DataFrame Spark.\n",
    "    \"\"\"\n",
    "\n",
    "    df =  spark.createDataFrame(deputados) \n",
    "\n",
    "    df = df.withColumn('data_ingestao', F.lit(datetime.now())) #adicionando as colunas de metadados\n",
    "    df = df.withColumn(\"url_origem\", F.lit(URL_DEPUTADOS)) #adicionando as colunas de metadados\n",
    "\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3f6ad4d5-aaf2-4da4-ab50-d042f001a41f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Funções nb_proposicoes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "collapsed": true,
     "inputWidgets": {},
     "nuid": "61daeef5-2892-4c7f-a39d-95064aefca66",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "URL_PROPOSICOES = \"https://dadosabertos.camara.leg.br/api/v2/proposicoes\"\n",
    "\n",
    "\n",
    "\n",
    "def get_proposicoes(pagina=1, itens =100, ano=None, siglaTipo=None):\n",
    "    \n",
    "    \"\"\"\n",
    "    Busca a lista de proposições da API.\n",
    "    pagina: número da página (Obrigatório)\n",
    "    itens: número de itens por página (máx 100) (Obrigatório)\n",
    "    ano: ano da proposição (opcional)\n",
    "    siglaTipo: sigla do tipo da proposição (opcional)\n",
    "    return: retorna a lista de proposições\n",
    "    \"\"\"\n",
    "\n",
    "    params = {k: v for k, v in {\n",
    "        \"pagina\": pagina,\n",
    "        \"itens\": itens,\n",
    "        \"ano\": ano,\n",
    "        \"siglaTipo\": siglaTipo\n",
    "    }.items() if v is not None\n",
    "    }\n",
    "    response = requests.get(URL_PROPOSICOES, params=params)\n",
    "    if not response:\n",
    "        return []\n",
    "\n",
    "    return response.json()[\"dados\"]\n",
    "\n",
    "def get_all_proposicoes(itens_por_pagina=100, limite_paginas=None, ano=None, siglaTipo=None):\n",
    "    \n",
    "    \"\"\"\n",
    "    Busca a lista de proposições, considerando a paginação.\n",
    "    itens_por_pagina: máximo de registros por página (default 100)\n",
    "    limite_paginas: Quais páginas, onde None = todas disponíveis\n",
    "    ano: ano da proposição (opcional)\n",
    "    siglaTipo: sigla do tipo da proposição (opcional)\n",
    "    return: lista de proposições\n",
    "    \"\"\"\n",
    "\n",
    "    proposicoes = []\n",
    "    pagina = 1\n",
    "    while True:\n",
    "        dados = get_proposicoes(pagina=pagina, itens=itens_por_pagina, ano=ano, siglaTipo=siglaTipo)\n",
    "        if not dados:\n",
    "            break\n",
    "        proposicoes.extend(dados)\n",
    "        print(f\"Página {pagina} carregada ({len(dados)} registros)\")\n",
    "        pagina += 1\n",
    "        if limite_paginas and pagina > limite_paginas:\n",
    "            break\n",
    "    return proposicoes\n",
    "    \n",
    "def proposicoes_to_dataframe(proposicoes):\n",
    "    \n",
    "    \"\"\"\n",
    "    Converte lista de proposições para DataFrame Spark.\n",
    "    \"\"\"\n",
    "\n",
    "    df = spark.createDataFrame(proposicoes)\n",
    "\n",
    "    df = df.withColumn('data_ingestao', F.lit(datetime.now())) #adicionando as colunas de metadados\n",
    "    df = df.withColumn(\"url_origem\", F.lit(URL_PROPOSICOES)) #adicionando as colunas de metadados\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "88c96c6b-35bf-403c-8c8a-3b20cefcf457",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Funções nb_votacoes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "collapsed": true,
     "inputWidgets": {},
     "nuid": "31a17681-119d-4a20-a59c-936882f26140",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "URL_VOTACOES = \"https://dadosabertos.camara.leg.br/api/v2/votacoes\"\n",
    "\n",
    "\n",
    "def get_votacoes(pagina=1, itens=100,dataInicio=None, dataFim=None):\n",
    "    \"\"\"\n",
    "    Busca votações por página.\n",
    "    \"\"\"\n",
    "\n",
    "    params = {k: v for k, v in{\n",
    "        \"pagina\": pagina,\n",
    "        \"itens\": itens,\n",
    "        \"dataInicio\": dataInicio,\n",
    "        \"dataFim\": dataFim\n",
    "    }.items() if v is not None}\n",
    "\n",
    "    response = safe_get(URL_VOTACOES, params=params)\n",
    "    if not response:\n",
    "        return []\n",
    "\n",
    "    return response.json()[\"dados\"]\n",
    "\n",
    "def get_all_votacoes(itens_pagina=100, limite_pagina=None, dataInicio=None, dataFim=None):\n",
    "\n",
    "    \"\"\"\n",
    "    Busca todas as votações da Câmara com paginação\n",
    "    \"\"\"\n",
    "\n",
    "    votacoes = []\n",
    "    pagina = 1\n",
    "    while True:\n",
    "        dados = get_votacoes(pagina=pagina, itens=itens_pagina, dataInicio=dataInicio, dataFim=dataFim)\n",
    "        if not dados:\n",
    "            break\n",
    "        votacoes.extend(dados)\n",
    "        print(f\"Página {pagina} carregada ({len(dados)} registros)\")\n",
    "        pagina +=1\n",
    "        if limite_pagina and pagina > limite_pagina:\n",
    "            break\n",
    "    return votacoes\n",
    "    \n",
    "def votacoes_to_dataframe(votacoes):\n",
    "\n",
    "    \"\"\"\n",
    "    Converte lista de votações para DataFrame Spark.\n",
    "    \"\"\"\n",
    "\n",
    "    df = spark.createDataFrame(votacoes)\n",
    "\n",
    "    df = df.withColumn('data_ingestao', F.lit(datetime.now())) #adicionando as colunas de metadados\n",
    "    df = df.withColumn(\"url_origem\", F.lit(URL_VOTACOES)) #adicionando as colunas de metadados\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "20846f0d-3e24-4913-9573-6e8df9be00ea",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Funções nb_eventos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4cce5e21-82f5-425e-b70d-e0c17fc71ba5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "URL_EVENTOS = \"https://dadosabertos.camara.leg.br/api/v2/eventos\"\n",
    "\n",
    "\n",
    "def get_eventos(pagina=1, itens=100, dataInicio=None, dataFim=None):\n",
    "\n",
    "    \"\"\"\n",
    "    Busca eventos da API da Câmara.\n",
    "    pagina: número da página (obrigatório)\n",
    "    itens: nº máximo de registros por página (máx=100)\n",
    "    dataInicio: filtrar a partir desta data (yyyy-mm-dd)\n",
    "    dataFim: filtrar até esta data (yyyy-mm-dd)\n",
    "    \"\"\"\n",
    "\n",
    "    params = {\n",
    "        \"pagina\": pagina,\n",
    "        \"itens\": itens,\n",
    "        \"dataInicio\": dataInicio,\n",
    "        \"dataFim\": dataFim\n",
    "    }\n",
    "    params = {k: v for k, v in params.items() if v is not None}\n",
    "\n",
    "    response = safe_get(URL_EVENTOS, params=params)\n",
    "    if not response:\n",
    "        return []\n",
    "    return response.json()[\"dados\"]\n",
    "\n",
    "\n",
    "def get_all_eventos(itens_por_pagina=100, limite_paginas=None, dataInicio=None, dataFim=None):\n",
    "\n",
    "    \"\"\"\n",
    "    Lista todos os eventos (com paginação)\n",
    "    \"\"\"\n",
    "\n",
    "    eventos = []\n",
    "    pagina = 1\n",
    "    while True:\n",
    "        dados = get_eventos(pagina=pagina, itens=itens_por_pagina,\n",
    "                            dataInicio=dataInicio, dataFim=dataFim)\n",
    "        if not dados:\n",
    "            break\n",
    "        eventos.extend(dados)\n",
    "        print(f\"Página {pagina} carregada ({len(dados)} registros)\")\n",
    "        pagina += 1\n",
    "        if limite_paginas and pagina > limite_paginas:\n",
    "            break\n",
    "    return eventos\n",
    "\n",
    "\n",
    "\n",
    "def eventos_to_dataframe(eventos):\n",
    "    \n",
    "    \"\"\"\n",
    "    Converte lista de eventos para DataFrame Spark.\n",
    "    \"\"\"\n",
    "\n",
    "    df = spark.createDataFrame(eventos)\n",
    "    df = df.withColumn(\"data_ingestao\", F.lit(datetime.now())) #adicionando as colunas de metadados\n",
    "    df = df.withColumn(\"url_origem\", F.lit(URL_EVENTOS)) #adicionando as colunas de metadados\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3ea777cb-a918-4101-87b7-2063f23a8c30",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Função - Salva Dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "28292496-4045-4dbf-837a-9274ab2eb2af",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def save_data(df, tabela=\"dados_bronze\"):\n",
    "    \n",
    "    \"\"\"\n",
    "    Salva o DataFrame como tabela no Databricks.\n",
    "    tabela: Nome da tabela a ser criada\n",
    "    \"\"\"\n",
    "    \n",
    "    spark.sql(f'DROP TABLE IF EXISTS {tabela}')\n",
    "    df.write.saveAsTable(tabela)\n",
    "    print(f\"Tabela '{tabela}' criada/atualizada com sucesso!\") #validações dos parâmetros"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3bb04895-f8eb-436c-b666-8cc4020a86e0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Funções nb_despesas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7cc22206-f609-4228-8f37-95bc502de6ca",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "path_volume = \"/Volumes/tiller/information_schema/volume_tiller/\"\n",
    "\n",
    "def load_despesas_csv(path_volume):\n",
    "    \"\"\"\n",
    "    Lê todos os arquivos CSV do volume informado\n",
    "    \"\"\"\n",
    "    try:\n",
    "        print(f\"Lendo arquivos CSV do volume: {path_volume}\")\n",
    "\n",
    "        \n",
    "        df = (\n",
    "        spark.read # Lê os arquivos CSV usando o spark.read\n",
    "        .option(\"header\", \"true\")\n",
    "        .option(\"inferSchema\", \"true\")\n",
    "        .option(\"sep\", \";\")     \n",
    "        .csv(f\"{path_volume}/*.csv\")\n",
    "    )\n",
    "        \n",
    "        for col in df.columns:\n",
    "            clean_col = (\n",
    "                col.strip()\n",
    "                .replace(\" \", \"_\") # Corrige nomes de colunas\n",
    "                .replace(\";\", \"_\")\n",
    "                .replace(\"(\", \"\")\n",
    "                .replace(\")\", \"\")\n",
    "            )\n",
    "            if clean_col != col:\n",
    "                df = df.withColumnRenamed(col, clean_col)\n",
    "\n",
    "        \n",
    "        df = df.withColumn(\"fonte_arquivo\", F.col(\"_metadata.file_path\")) # Adiciona a coluna de origem \n",
    "\n",
    "        print(\"Arquivos CSV lidos e colunas tratadas com sucesso!\")\n",
    "        return df\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Erro na leitura dos arquivos CSV: {e}\")\n",
    "        return None\n",
    "    \n",
    "def process_despesas_bronze():\n",
    "    \"\"\"\n",
    "    Processa e salva os arquivos no formato Delta.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        despesas = load_despesas_csv(\"/Volumes/tiller/information_schema/volume_tiller/\")\n",
    "\n",
    "        # 🧩 Se não conseguiu ler, encerra\n",
    "        if despesas is None:\n",
    "            print(\"Nenhum DataFrame retornado pela leitura. Interrompendo.\")\n",
    "            return None\n",
    "\n",
    "        # 🧩 Se o DataFrame estiver vazio, encerra\n",
    "        if despesas.count() == 0:\n",
    "            print(\"DataFrame vazio. Nenhum registro para processar.\")\n",
    "            return None\n",
    "\n",
    "        print(\"Schema do DataFrame:\")\n",
    "        despesas.printSchema()\n",
    "\n",
    "        print(\"Amostra de registros:\")\n",
    "        despesas.show(5, truncate=False)\n",
    "\n",
    "        # Salva a tabela\n",
    "        save_data(despesas, \"tb_despesas_bronze\")\n",
    "\n",
    "        print(\"Tabela 'tb_despesas_bronze' criada/atualizada com sucesso!\")\n",
    "        return despesas\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Erro ao processar discursos: {e}\")\n",
    "        return None\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "3"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 4744943781841291,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "nb_bronze_functions",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
